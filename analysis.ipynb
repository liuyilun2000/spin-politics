{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import umap.umap_ as umap\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_pickle(\"/home/hpc/b207dd/b207dd11/test/spin-politics/standard_text_with_embeddings.pkl\")\n",
    "WORK_DIR = \"/home/hpc/b207dd/b207dd11/test/spin-politics\"\n",
    "\n",
    "model_name = \"llama3-8b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STANDARD_ACTIVATIONS_CACHE_DIR = f\"/home/atuin/b207dd/b207dd11/test/DEU/standard_sentences/{model_name}\"\n",
    "\n",
    "\n",
    "df.to_pickle(f\"{STANDARD_ACTIVATIONS_CACHE_DIR}/standard_text_with_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to convert categorical values to RGB values\n",
    "def category_to_rgb(libertarian, collectivist, progressive):\n",
    "    color_map = {\n",
    "        \"Neutral\": 128,\n",
    "        \"Libertär\": 225,\n",
    "        \"Restriktiv\": 30,\n",
    "        \"Kollektivistisch\": 225,\n",
    "        \"Individualistisch\": 30,\n",
    "        \"Progressiv\": 225,\n",
    "        \"Konservativ\": 30\n",
    "    }\n",
    "    r = color_map[libertarian]\n",
    "    g = color_map[collectivist]\n",
    "    b = color_map[progressive]\n",
    "    return f'rgb({r},{g},{b})'\n",
    "\n",
    "df['Ideology'] = df['Libertarian'] + ' - ' + df['Collectivist'] + ' - ' + df['Progressive']\n",
    "df['Color'] = df.apply(lambda row: category_to_rgb(row['Libertarian'], row['Collectivist'], row['Progressive']), axis=1)\n",
    "# Create a color discrete map\n",
    "unique_ideologies = df['Ideology'].unique()\n",
    "color_discrete_map = {ideology: color for ideology, color in zip(unique_ideologies, df['Color'].unique())}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised PCA + UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pca_umap_plot(df, \n",
    "                  pca_cumul_var_ratio_thresh=None,\n",
    "                  pca_n_components=None, \n",
    "                  umap_n_components=3, \n",
    "                  umap_n_neighbors=15, \n",
    "                  umap_min_dist=0.1, \n",
    "                  layer_list=None,\n",
    "                  image_output_folder=\"\"):\n",
    "    embeddings = np.stack(df['Embedding'].values)\n",
    "    n_layers = embeddings.shape[1]\n",
    "    if layer_list is None:\n",
    "        layer_list = range(n_layers)\n",
    "    #\n",
    "    for layer in tqdm(layer_list, desc=\"Processing layers\"):\n",
    "        layer_embeddings = embeddings[:, layer, :]\n",
    "        # Standardize embeddings\n",
    "        mean = np.mean(layer_embeddings, axis=0)\n",
    "        std = np.std(layer_embeddings, axis=0)\n",
    "        standardized_embeddings = (layer_embeddings - mean) / std\n",
    "        # PCA\n",
    "        if pca_n_components:\n",
    "            num_components = pca_n_components\n",
    "            pca = PCA(n_components=num_components)\n",
    "            pca_embeddings = pca.fit_transform(standardized_embeddings)\n",
    "        elif pca_cumul_var_ratio_thresh:\n",
    "            pca = PCA()\n",
    "            pca.fit(standardized_embeddings)\n",
    "            cumul_var_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "            num_components = np.where(cumul_var_ratio >= pca_cumul_var_ratio_thresh)[0][0] + 1\n",
    "            if num_components < umap_n_components:\n",
    "                num_components = umap_n_components\n",
    "            pca_embeddings = pca.transform(standardized_embeddings)[:, :num_components]\n",
    "        print(f\"Layer {layer} PCA num_components {num_components}\")\n",
    "        # UMAP\n",
    "        if umap_n_components < num_components:\n",
    "            umap_reducer = umap.UMAP(n_components=umap_n_components, \n",
    "                                    n_neighbors=umap_n_neighbors, \n",
    "                                    min_dist=umap_min_dist, \n",
    "                                    metric='cosine', \n",
    "                                    random_state=42)\n",
    "            umap_embeddings = umap_reducer.fit_transform(pca_embeddings)\n",
    "        else:\n",
    "            umap_embeddings = pca_embeddings\n",
    "        # df for plotting\n",
    "        plot_df = df.copy()\n",
    "        plot_df['UMAP1'] = umap_embeddings[:, 0]\n",
    "        plot_df['UMAP2'] = umap_embeddings[:, 1]\n",
    "        plot_df['UMAP3'] = umap_embeddings[:, 2] if umap_n_components == 3 else np.zeros(umap_embeddings.shape[0])\n",
    "        # Plotting\n",
    "        fig = px.scatter_3d(\n",
    "            plot_df, x='UMAP1', y='UMAP2', z='UMAP3', \n",
    "            color='Ideology', \n",
    "            color_discrete_map=color_discrete_map,\n",
    "            #color_continuous_scale=px.colors.sequential.Rainbow_r,\n",
    "            #color_discrete_sequence=px.colors.sequential.Rainbow_r,\n",
    "            title=f'Layer {layer} Embeddings',\n",
    "            hover_data={\n",
    "                'Libertarian': True,\n",
    "                'Collectivist': True,\n",
    "                'Progressive': True,\n",
    "                'Topic': True,\n",
    "                #'Response': True\n",
    "            }\n",
    "        )\n",
    "        file_path = f'{image_output_folder}/scatter_layer{layer}_pca{num_components}_umap{umap_n_components}.html'\n",
    "        fig.write_html(file_path)\n",
    "        plt.close()\n",
    "        plt.clf()\n",
    "\n",
    "# Call the function\n",
    "pca_umap_plot(\n",
    "    df, \n",
    "    #pca_cumul_var_ratio_thresh=.5,\n",
    "    pca_n_components=3, \n",
    "    umap_n_components=3, \n",
    "    umap_n_neighbors=100, \n",
    "    umap_min_dist=0.8, \n",
    "    #layer_list=[i for i in range(3)],\n",
    "    image_output_folder=f\"{WORK_DIR}/standard_img\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised (Manual) Axis Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate mean embeddings and filter significant features\n",
    "def calculate_mean_embeddings_with_filter(df, axis, p_value_threshold=5e-12):\n",
    "    type_a_label = axis[\"type_a\"]\n",
    "    type_b_label = axis[\"type_b\"]\n",
    "    #\n",
    "    type_a_embeddings = np.stack(df[df[axis[\"column\"]] == type_a_label]['Embedding'].values)\n",
    "    type_b_embeddings = np.stack(df[df[axis[\"column\"]] == type_b_label]['Embedding'].values)\n",
    "    print(type_a_embeddings.shape, type_b_embeddings.shape)\n",
    "    # Calculate mean and variance\n",
    "    type_a_mean = np.mean(type_a_embeddings, axis=0)\n",
    "    type_b_mean = np.mean(type_b_embeddings, axis=0)\n",
    "    #\n",
    "    type_a_var = np.var(type_a_embeddings, axis=0)\n",
    "    type_b_var = np.var(type_b_embeddings, axis=0)\n",
    "    # Perform t-test for each feature\n",
    "    t_values, p_values = ttest_ind(type_a_embeddings, type_b_embeddings, axis=0, equal_var=False)\n",
    "    # Create filter for significant features\n",
    "    significant_features = p_values < p_value_threshold\n",
    "    # Calculate direction vector using only significant features\n",
    "    direction_vector = np.zeros_like(type_a_mean)\n",
    "    direction_vector[significant_features] = type_a_mean[significant_features] - type_b_mean[significant_features]\n",
    "    # Normalize the direction vector\n",
    "    #norm = np.linalg.norm(direction_vector)\n",
    "    #if norm != 0:\n",
    "    #    direction_vector /= norm    \n",
    "    return direction_vector, significant_features\n",
    "\n",
    "# Define the axes\n",
    "axes = {\n",
    "    \"Libertarian\": {\"column\": \"Libertarian\", \"type_a\": \"Libertär\", \"type_b\": \"Restriktiv\"},\n",
    "    \"Collectivist\": {\"column\": \"Collectivist\", \"type_a\": \"Kollektivistisch\", \"type_b\": \"Individualistisch\"},\n",
    "    \"Progressive\": {\"column\": \"Progressive\", \"type_a\": \"Progressiv\", \"type_b\": \"Konservativ\"}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Calculate mean embeddings and filters for each axis\n",
    "mean_embeddings = {}\n",
    "significant_features = {}\n",
    "for axis_name, axis in axes.items():\n",
    "    mean_embeddings[axis_name], significant_features[axis_name] = calculate_mean_embeddings_with_filter(df_standard, axis)\n",
    "    num_significant_features = np.sum(significant_features[axis_name])\n",
    "    total_features = significant_features[axis_name].size\n",
    "    print(f\"{axis_name}: {num_significant_features} of {total_features} features used\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new DataFrame for plotting\n",
    "plot_data = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing rows\"):\n",
    "    embedding = row['Embedding']    \n",
    "    # Apply the significant feature filter to the embeddings\n",
    "    filtered_embedding = {}\n",
    "    for axis_name in axes.keys():\n",
    "        filtered_embedding[axis_name] = embedding * significant_features[axis_name]\n",
    "    # Calculate scores for each axis using only significant features\n",
    "    libertarian_score = np.dot(filtered_embedding[\"Libertarian\"].flatten(), mean_embeddings[\"Libertarian\"].flatten())\n",
    "    collectivist_score = np.dot(filtered_embedding[\"Collectivist\"].flatten(), mean_embeddings[\"Collectivist\"].flatten())\n",
    "    progressive_score = np.dot(filtered_embedding[\"Progressive\"].flatten(), mean_embeddings[\"Progressive\"].flatten())\n",
    "    #\n",
    "    plot_data.append({\n",
    "        'Libertarian': row['Libertarian'],\n",
    "        'Collectivist': row['Collectivist'],\n",
    "        'Progressive': row['Progressive'],\n",
    "        'Topic': row['Topic'],\n",
    "        \"Libertarian\": libertarian_score,\n",
    "        \"Collectivist\": collectivist_score,\n",
    "        \"Progressive\": progressive_score,\n",
    "        \"Ideology\": row[\"Ideology\"]\n",
    "    })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Plotting\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    plot_df, x='Libertarian', y='Collectivist', z='Progressive', \n",
    "    color='Ideology', \n",
    "    color_discrete_map=color_discrete_map,\n",
    "    #color_continuous_scale=px.colors.sequential.Rainbow_r,\n",
    "    #color_discrete_sequence=px.colors.sequential.Rainbow_r,\n",
    "    title=f'Manual Axes Embeddings',\n",
    "    hover_data={\n",
    "        'Libertarian': True,\n",
    "        'Collectivist': True,\n",
    "        'Progressive': True,\n",
    "        'Topic': True,\n",
    "        #'Response': True\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "image_output_folder=f\"{WORK_DIR}/standard_img\"\n",
    "file_path = f'{image_output_folder}/scatter_manual.html'\n",
    "fig.write_html(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_speech_filtered_concat = pd.read_pickle('df_speech_filtered_concat.pkl')\n",
    "\n",
    "\n",
    "\n",
    "# Function to load embeddings from a tensor file\n",
    "def load_embedding(index, path):\n",
    "    file_path = f\"{path}/{index}.pt\"\n",
    "    return torch.load(file_path, map_location='cpu')\n",
    "\n",
    "# Load all real text activations and add them to the DataFrame\n",
    "ACTIVATIONS_CACHE_DIR = f\"/home/atuin/b207dd/b207dd11/test/DEU/activations/{model_name}\"\n",
    "real_text_embeddings = []\n",
    "\n",
    "for index in tqdm(range(len(df_speech_filtered_concat))):\n",
    "    real_text_embeddings.append(load_embedding(index, ACTIVATIONS_CACHE_DIR).numpy())\n",
    "\n",
    "df_speech_filtered_concat['Embedding'] = real_text_embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_speech_filtered_concat.to_pickle(f\"{ACTIVATIONS_CACHE_DIR}/df_speech_filtered_concat.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_embedding(embeddings):\n",
    "    return np.mean(np.stack(embeddings), axis=0)\n",
    "\n",
    "\n",
    "# Group by 'Speaker' and calculate mean embedding and count of entries\n",
    "speaker_data = []\n",
    "\n",
    "for speaker, group in tqdm(df_speech_filtered_concat.groupby('Speaker')):\n",
    "    mean_embedding = calculate_mean_embedding(group['Embedding'].values)\n",
    "    if np.isnan(mean_embedding).any():\n",
    "        print(group)\n",
    "    speaker_info = group.iloc[0][['Speaker', 'Partei', 'Religion']]\n",
    "    entry_count = len(group)\n",
    "    speaker_data.append({\n",
    "        **speaker_info,\n",
    "        \"Embedding\": mean_embedding,\n",
    "        \"EntryCount\": entry_count\n",
    "    })\n",
    "\n",
    "# Create a new DataFrame from the speaker data\n",
    "df_speaker_mean_embeddings = pd.DataFrame(speaker_data)\n",
    "\n",
    "# Save the new DataFrame to a pickle file\n",
    "df_speaker_mean_embeddings.to_pickle(f\"{ACTIVATIONS_CACHE_DIR}/df_speaker_mean_embeddings.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting\n",
    "party_color_discrete_map = {\n",
    "    'SPD': '#E3000F',          # Red\n",
    "    'BÜNDNIS 90/DIE GRÜNEN': '#46962B',  # Green\n",
    "    'CSU': '#008AC5',          # Blue\n",
    "    'CDU': '#000000',          # Black\n",
    "    'AfD': '#009EE0',          # Light Blue\n",
    "    'FDP': '#FFED00',          # Yellow\n",
    "    'DIE LINKE.': '#BE3075'    # Magenta\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pca_umap_plot(df, \n",
    "                  pca_cumul_var_ratio_thresh=None,\n",
    "                  pca_n_components=None, \n",
    "                  umap_n_components=3, \n",
    "                  umap_n_neighbors=15, \n",
    "                  umap_min_dist=0.1, \n",
    "                  layer_list=None,\n",
    "                  image_output_folder=\"\"):\n",
    "    embeddings = np.stack(df['Embedding'].values)\n",
    "    n_layers = embeddings.shape[1]\n",
    "    if layer_list is None:\n",
    "        layer_list = range(n_layers)\n",
    "    #\n",
    "    for layer in tqdm(layer_list, desc=\"Processing layers\"):\n",
    "        layer_embeddings = embeddings[:, layer, :]\n",
    "        # Standardize embeddings\n",
    "        mean = np.mean(layer_embeddings, axis=0)\n",
    "        std = np.std(layer_embeddings, axis=0)\n",
    "        standardized_embeddings = (layer_embeddings - mean) / std\n",
    "        # PCA\n",
    "        if pca_n_components:\n",
    "            num_components = pca_n_components\n",
    "            pca = PCA(n_components=num_components)\n",
    "            pca_embeddings = pca.fit_transform(standardized_embeddings)\n",
    "        elif pca_cumul_var_ratio_thresh:\n",
    "            pca = PCA()\n",
    "            pca.fit(standardized_embeddings)\n",
    "            cumul_var_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "            num_components = np.where(cumul_var_ratio >= pca_cumul_var_ratio_thresh)[0][0] + 1\n",
    "            if num_components < umap_n_components:\n",
    "                num_components = umap_n_components\n",
    "            pca_embeddings = pca.transform(standardized_embeddings)[:, :num_components]\n",
    "        print(f\"Layer {layer} PCA num_components {num_components}\")\n",
    "        # UMAP\n",
    "        if umap_n_components < num_components:\n",
    "            umap_reducer = umap.UMAP(n_components=umap_n_components, \n",
    "                                    n_neighbors=umap_n_neighbors, \n",
    "                                    min_dist=umap_min_dist, \n",
    "                                    metric='cosine', \n",
    "                                    random_state=42)\n",
    "            umap_embeddings = umap_reducer.fit_transform(pca_embeddings)\n",
    "        else:\n",
    "            umap_embeddings = pca_embeddings\n",
    "        # df for plotting\n",
    "        plot_df = df.copy()\n",
    "        plot_df['UMAP1'] = umap_embeddings[:, 0]\n",
    "        plot_df['UMAP2'] = umap_embeddings[:, 1]\n",
    "        plot_df['UMAP3'] = umap_embeddings[:, 2] if umap_n_components == 3 else np.zeros(umap_embeddings.shape[0])\n",
    "        # Plotting\n",
    "        fig = px.scatter_3d(\n",
    "            plot_df, x='UMAP1', y='UMAP2', z='UMAP3', \n",
    "            color='Partei', \n",
    "            size='EntryCount',\n",
    "            opacity=0.5,\n",
    "            color_discrete_map=party_color_discrete_map,\n",
    "            #color_continuous_scale=px.colors.sequential.Rainbow_r,\n",
    "            #color_discrete_sequence=px.colors.sequential.Rainbow_r,\n",
    "            title=f'Layer {layer} Real Speaker Activations on UMAP Axes',\n",
    "            hover_data={\n",
    "                'Speaker': True\n",
    "            }\n",
    "        )\n",
    "        #fig.update_traces(marker_size = 5)\n",
    "        file_path = f'{image_output_folder}/scatter_layer{layer}_pca{num_components}_umap{umap_n_components}.html'\n",
    "        fig.write_html(file_path)\n",
    "        plt.close()\n",
    "        plt.clf()\n",
    "\n",
    "# Call the function\n",
    "pca_umap_plot(\n",
    "    #df_speech_filtered_concat.sample(1000), \n",
    "    df_speaker_mean_embeddings.sort_values(by='EntryCount', ascending=False).iloc[6:],\n",
    "    #pca_cumul_var_ratio_thresh=.5,\n",
    "    pca_n_components=6, \n",
    "    umap_n_components=3, \n",
    "    umap_n_neighbors=20, \n",
    "    umap_min_dist=0.1, \n",
    "    #layer_list=[i for i in range(3)],\n",
    "    #image_output_folder=f\"{WORK_DIR}/real_1000_img\"\n",
    "    image_output_folder=f\"{WORK_DIR}/real_speaker_img\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for plotting\n",
    "plot_data = []\n",
    "\n",
    "for index, row in tqdm(df_speech_filtered_concat.iterrows(), total=df_speech_filtered_concat.shape[0], desc=\"Processing rows\"):\n",
    "    embedding = row['Embedding']\n",
    "    libertarian_score = np.dot(embedding.flatten(), mean_embeddings[\"Libertarian\"][0].flatten()) - np.dot(embedding.flatten(), mean_embeddings[\"Libertarian\"][1].flatten())\n",
    "    collectivist_score = np.dot(embedding.flatten(), mean_embeddings[\"Collectivist\"][0].flatten()) - np.dot(embedding.flatten(), mean_embeddings[\"Collectivist\"][1].flatten())\n",
    "    progressive_score = np.dot(embedding.flatten(), mean_embeddings[\"Progressive\"][0].flatten()) - np.dot(embedding.flatten(), mean_embeddings[\"Progressive\"][1].flatten())\n",
    "    #\n",
    "    plot_data.append({\n",
    "        \"Partei\": row[\"Partei\"],\n",
    "        \"Libertarian\": libertarian_score,\n",
    "        \"Collectivist\": collectivist_score,\n",
    "        \"Progressive\": progressive_score,\n",
    "        \"Text\": row[\"Text\"],\n",
    "    })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    plot_df, x='Libertarian', y='Collectivist', z='Progressive', \n",
    "    color='Partei', \n",
    "    opacity=0.5,\n",
    "    color_discrete_map=party_color_discrete_map,\n",
    "    #color_continuous_scale=px.colors.sequential.Rainbow_r,\n",
    "    #color_discrete_sequence=px.colors.sequential.Rainbow_r,\n",
    "    title=f'Real Text Activations on Manual Axes'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image_output_folder=f\"{WORK_DIR}/standard_img\"\n",
    "file_path = f'{image_output_folder}/scatter_real_data_manual.html'\n",
    "fig.write_html(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_speaker_mean_embeddings.sort_values(by='EntryCount', ascending=False).iloc[6:]\n",
    "# Create a new DataFrame for plotting\n",
    "plot_data = []\n",
    "\n",
    "for index, row in tqdm(df_tmp.iterrows(), total=df_tmp.shape[0], desc=\"Processing rows\"):\n",
    "    embedding = row['Embedding']\n",
    "    # Apply the significant feature filter to the embeddings\n",
    "    filtered_embedding = {}\n",
    "    for axis_name in axes.keys():\n",
    "        filtered_embedding[axis_name] = embedding * significant_features[axis_name]\n",
    "    # Calculate scores for each axis using only significant features\n",
    "    libertarian_score = np.dot(filtered_embedding[\"Libertarian\"].flatten(), mean_embeddings[\"Libertarian\"].flatten())\n",
    "    collectivist_score = np.dot(filtered_embedding[\"Collectivist\"].flatten(), mean_embeddings[\"Collectivist\"].flatten())\n",
    "    progressive_score = np.dot(filtered_embedding[\"Progressive\"].flatten(), mean_embeddings[\"Progressive\"].flatten())\n",
    "    #\n",
    "    plot_data.append({\n",
    "        \"Speaker\": row[\"Speaker\"],\n",
    "        \"Partei\": row[\"Partei\"],\n",
    "        \"Libertarian\": libertarian_score,\n",
    "        \"Collectivist\": collectivist_score,\n",
    "        \"Progressive\": progressive_score,\n",
    "        \"EntryCount\": row[\"EntryCount\"],\n",
    "        \"Symbol\": 'Speaker'\n",
    "    })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "\n",
    "# Calculate centroids for each party\n",
    "centroid_data = plot_df.groupby('Partei').agg({\n",
    "    'Libertarian': 'mean',\n",
    "    'Collectivist': 'mean',\n",
    "    'Progressive': 'mean',\n",
    "    'EntryCount': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "centroid_data['Speaker'] = centroid_data['Partei']  # Add a placeholder for Speaker\n",
    "centroid_data['Symbol'] = 'Partei'\n",
    "\n",
    "# Append centroids to plot_df\n",
    "plot_df = pd.concat([plot_df, centroid_data], ignore_index=True)\n",
    "\n",
    "libertarian_range = [plot_df['Libertarian'].min(), plot_df['Libertarian'].max()]\n",
    "collectivist_range = [plot_df['Collectivist'].min(), plot_df['Collectivist'].max()]\n",
    "progressive_range = [plot_df['Progressive'].min(), plot_df['Progressive'].max()]\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    plot_df, x='Libertarian', y='Collectivist', z='Progressive', \n",
    "    color='Partei', \n",
    "    size='EntryCount',\n",
    "    size_max=128,\n",
    "    symbol='Symbol',\n",
    "    symbol_map={'Partei':'circle', 'Speaker':'square'},\n",
    "    opacity=0.56,\n",
    "    color_discrete_map=party_color_discrete_map,\n",
    "    range_x=libertarian_range,\n",
    "    range_y=collectivist_range,\n",
    "    range_z=progressive_range,\n",
    "    #color_continuous_scale=px.colors.sequential.Rainbow_r,\n",
    "    #color_discrete_sequence=px.colors.sequential.Rainbow_r,\n",
    "    title=f'Real Speaker Activations on Manual Axes',\n",
    "    hover_data={\n",
    "        'Speaker': True\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "image_output_folder=f\"{WORK_DIR}/real_speaker_img\"\n",
    "file_path = f'{image_output_folder}/scatter_real_data_manual.html'\n",
    "fig.write_html(file_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
